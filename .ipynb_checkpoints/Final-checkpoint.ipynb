{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal for the project was to find the best neighborhood in Pittsburgh... if you were a dog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://media.giphy.com/media/8lMWzUYpCuLMIOkiCU/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chosing Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, dogs cannot collect & distribute their own data (although that would be pretty cool & helpful in our project). So we had to get creative. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first data set was parks! Dogs love exercise and to be outside. So we tried to find the neighborhood with most park area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next set was to look at the water sources in Pittsburgh. Dogs need water to stay healthy, even when they are outside of their household. so we tried to find the neighborhood with the most waterfountains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final set was looking at 311 requests. 311 requests are non-emergent situations that may need assistance. We were able to find reports of \"Barking Dogs\" to find where more dogs may be present. More dogs = more dog friends and a dog friendly neighborhood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bens Part!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Neighborhood for a dog in pittsburgh\n",
    "## By Park Area:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOGS LIKE PARKS!!!!\n",
    "### What neighborhood has the access to the most park area!!!\n",
    "\n",
    "\n",
    "![dog](https://media.giphy.com/media/ZNegC7wFpuQT7nurZ0/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File realData.csv does not exist: 'realData.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ce42a4998926>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#reading in my dataframe to make this dataset I used arcgis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#to split the neighborood csv by the park csv based on whether there was overlap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"realData.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#taking in the real data then cutting down the data set into important values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File realData.csv does not exist: 'realData.csv'"
     ]
    }
   ],
   "source": [
    "#reading in my dataframe to make this dataset I used arcgis\n",
    "#to split the neighborood csv by the park csv based on whether there was overlap\n",
    "data = pd.read_csv(\"realData.csv\")\n",
    "\n",
    "#taking in the real data then cutting down the data set into important values\n",
    "#then sorting them based on the park area \n",
    "data1 = data[['HOOD','Shape_Area', 'updatepknm','Shape__Are']]\n",
    "shapeData = data1.sort_values(by='Shape_Area',ascending=False)\n",
    "df = shapeData[['Shape__Are', 'HOOD', 'Shape_Area','updatepknm']]\n",
    "\n",
    "\n",
    "#this is the part where everything is added together if it has the same hood name\n",
    "aggregation_functions = {'Shape__Are': 'sum', 'Shape_Area': 'sum','HOOD': 'first','updatepknm': 'sum'}\n",
    "\n",
    "df_new = df.groupby(df['HOOD']).aggregate(aggregation_functions)\n",
    "df_new = df_new.sort_values(by='Shape__Are',ascending=False)\n",
    "df_new = df_new[['HOOD', 'updatepknm','Shape__Are']]\n",
    "\n",
    "\n",
    "#this is the graphing part\n",
    "df_new[0:20].plot(kind='barh',rot = 0, figsize=(12,12), title=\"Total Park area by neighborhood\").invert_yaxis()\n",
    "plt.style.use('seaborn-pastel')\n",
    "df_new[0:10].plot.pie(y='Shape__Are', figsize=(12,12), fontsize=20, title=\"Total Park area by neighborhood (pieChart)\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Above is a bar graph and a pie chart representing the area of parks by neighborhood, squirrel hill south is shown to have "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a list of the neighborhood\n",
    "#### it shows the top 30 neighborhoods, the parks that are in there, then the total park area "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new[['updatepknm','Shape__Are']]\n",
    "df_new.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this is a test to confirm that the addition of each neighborhood works\n",
    "This adds the data in a different way, as you can see it matches the data above. meaning that the addition method I did probably worked as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"realData.csv\")\n",
    "\n",
    "data1 = data[['HOOD','Shape_Area', 'updatepknm','Shape__Are']]\n",
    "data1 = data1.sort_values(by='HOOD')\n",
    "shapeData = data1.sort_values(by='Shape_Area',ascending=False)\n",
    "\n",
    "sqs = shapeData[shapeData.HOOD == \"Squirrel Hill South\"]\n",
    "sqs = sqs[[\"Shape__Are\"]]\n",
    "sqSum = sqs.sum()\n",
    "print(sqSum, \"sq of total park in squirrel hill south\")\n",
    "\n",
    "#npNumbers = data[data.Park_Name == \"North Park\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data from above shows that the top Three neighborhoods with the most parks are: \n",
    "## #1)Squirrel hill south\n",
    "### #2)Point Breeze\n",
    "#### #3)Swisshelmpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods = geopandas.read_file(\"Neighborhoods/Neighborhoods_.shp\") # read in the shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map = neighborhoods.merge(df_new, how='left', left_on='hood', right_on='HOOD')\n",
    "df_map.head()\n",
    "df_map.plot(column='Shape__Are_y',# set the data to be used for coloring\n",
    "               cmap='BuGn',              # choose a color palette\n",
    "               edgecolor=\"white\",        # outline the districts in white\n",
    "               legend=True,              # show the legend\n",
    "               legend_kwds={'label': \"ParkSize\"}, # label the legend\n",
    "               figsize=(15, 10),         # set the size # set disctricts with no data to gray\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conclusion:\n",
    "The data shows that squirrel hill south has the most total paark area per neighborhood by far, this shows that when it comes to dogs excersise and enjoyment of the park squirrel hill south cant be beat.\n",
    "![dog](https://media.giphy.com/media/PSKAppO2LH56w/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jackie's Part!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Water Fountains in Neighborhoods\n",
    "##### Everyone knows that dogs, like most living things, need water to survive. When someone is walking their dog, it's important for them to make sure that they have access to water. So, when picking the best neighborhood for your dog, you should consider the amount of water fountains that are in the neighborhood.\n",
    "![dog at water fountain](https://64.media.tumblr.com/c5c491671ef9edda5508d3285a41302a/tumblr_n6lhmnXMng1tv4atfo1_500.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Dataset\n",
    "This dataset shows all the water fountains within Pittsburgh. It also gives the type of fountain, the neighorhood it is in, the park or area it is in, and the coordinates of the fountain, among other things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data and display chart\n",
    "water = pd.read_csv(\"WaterFountains.csv\")\n",
    "water"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starting to Scale Down\n",
    "We really only need to consider drinking fountains as far as keeping our dog hydrated goes. So here, I used a query mask in order to create a dataset with just the drinking fountains. You can see that dataset below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query mask for just drinking fountains\n",
    "query_mask = water['feature_type'] == 'Drinking Fountain'\n",
    "fountains = water[query_mask]\n",
    "fountains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting it out\n",
    "Now for this to be useful and only show what I really need, I put the neighborhoods in a dictionary and then used a loop to count how many drinking fountains were in each neighborhood. Then, I took the dictionary and created a dataset with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create set that says how many water fountains are in each neighborhood\n",
    "neighborhood_list = fountains['neighborhood'].tolist()\n",
    "fountainDict = {}\n",
    "count = 0\n",
    "fountain_neighborhood = []\n",
    "#Creating a dictionary of neighborhoods and how many water fountains are in each\n",
    "while count < 191:\n",
    "    hood = neighborhood_list[count]\n",
    "    if hood in fountainDict:\n",
    "        fountainDict[hood] = fountainDict[hood] + 1\n",
    "    else:\n",
    "        fountainDict[hood] = 1\n",
    "        fountain_neighborhood.append(hood)\n",
    "    count = count + 1\n",
    "fountainDict\n",
    "\n",
    "#Creating a series with that dictionary\n",
    "amount_of_fountains = []   \n",
    "fountain_series = pd.Series(fountainDict)\n",
    "fountain_series\n",
    "\n",
    "#Create the dataframe with that series\n",
    "for hood in fountain_neighborhood:\n",
    "    amount_of_fountains.append(fountainDict[hood])\n",
    "fountain_df = pd.DataFrame(amount_of_fountains, fountain_neighborhood)\n",
    "fountain_df.columns = ['amount_of_fountains']\n",
    "fountain_df.index.name = 'neighborhood'\n",
    "fountain_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Top Neighborhoods\n",
    "There are still quite a few neighborhoods in this dataset. In order to compare easily, I needed to narrow down the dataset even further by isolating the neighborhoods that had more than a couple of fountains. You can see the comparison very clearly in the bar graph below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query mask to filter out smaller values\n",
    "query_mask = fountain_df['amount_of_fountains'] > 4\n",
    "filtered_fountain = fountain_df[query_mask]\n",
    "filtered_fountain.plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_fountain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the significant difference in water fountains between neighborhoods. Squirrel Hill South has the most, with Highland Park a few behind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put it on the Map!\n",
    "A bar graph is one good way to compare neighborhoods, but what if you want to visualize it more? That's where a map comes in! Below, I used geopandas to merge the the map shape and the water fountain dataset (with all neighborhoods, not just the ones with the most fountains). Finally, I plotted the map, and now you can see where there are more water fountains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoodmap = geopandas.read_file(\"Map/Neighborhoods.shp\")\n",
    "# do the merge\n",
    "fountain_map = neighborhoodmap.merge(fountain_df, how='left', left_on='hood', right_on='neighborhood')\n",
    "fountain_map['amount_of_fountains'] = fountain_map['amount_of_fountains'].fillna(0)\n",
    "# look at the head to confirm it merged correctly\n",
    "fountain_map[['hood','amount_of_fountains','geometry']]\n",
    "fountain_map.plot(column='amount_of_fountains', # set the data to be used for coloring\n",
    "               cmap='Blues',              # choose a color palette\n",
    "               edgecolor=\"black\",        # outline the districts in white\n",
    "               legend=True,              # show the legend\n",
    "               legend_kwds={'label': \"Amount of Fountains\"}, # label the legend\n",
    "               figsize=(15, 10),         # set the size\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "Based on the data above, one can clearly tell that Squirrel Hill South has the most drinking fountains. While most neighborhoods have at least one, many do not have more than a couple, and only two neighborhoods, including Squirrel Hill South, have over ten. Squirrel Hill is far superior in terms of drinking fountains, so if you live there, one could say that you would be *swimming* in water (get it?).\n",
    "\n",
    "![singing in rain guy jumping aroung in water](https://media0.giphy.com/media/m9HKyqt4Xauic/giphy.gif?cid=ecf05e4727u9z8xgryrwaosdtilmnuxajiu63wv57y2y0lhj&rid=giphy.gif&ct=g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Giovanna's part!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Neighborhood in Pittsburgh for Dogs (Giovanna's Part)\n",
    "![alt text](https://media.giphy.com/media/fIrbAgjX4Gjqo/giphy-downsized-large.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dogs like friends! Which neighborhoods have the most dog friends?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "311 is the non-emergency helpline in Pittsburgh. There were previously 500,000 rows of complaints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filters out all requests besides \"Barking Dog\"\n",
    "data = pd.read_csv(\"311.csv\", index_col=\"NEIGHBORHOOD\", parse_dates=True)\n",
    "dogStuff = data[data.REQUEST_TYPE == \"Barking Dog\"]\n",
    "dogStuff.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogStuff.groupby(\"NEIGHBORHOOD\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogStuff.groupby(['NEIGHBORHOOD','REQUEST_TYPE']).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code removes neighborhoods with less than 10 complaints\n",
    "def filter_by_barks (x, threshold):\n",
    "    if len(x) > threshold:\n",
    "        return True\n",
    "    else: \n",
    "        return False\n",
    "\n",
    "dog_friends = dogStuff.groupby(\"NEIGHBORHOOD\").filter(filter_by_barks, \n",
    "                                                      threshold=10)\n",
    "\n",
    "dog_friends.groupby(\"NEIGHBORHOOD\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogFriends = dog_friends.groupby(['NEIGHBORHOOD']).size().sort_values(ascending=False)\n",
    "dogFriends.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-pastel')\n",
    "dogFriends.plot.barh(title = 'Barking Dogs in PGH', x= 'Neighborhood', y='Barking Dogs', figsize=(12,12)).invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now a pie chart\n",
    "plt.style.use('seaborn-pastel')\n",
    "dogFriends.plot.pie(figsize = (12,12), title= 'Barking Dogs in PGH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We discovered that Brookline is the neighborhood with the most barking dogs. However, this not the only metric that we took into consideration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL CONCLUSION\n",
    "here is the end part (i hope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what am i doing?\n",
    "First I normalized all the data to make it similar to eachother then I added all the data to a new data frame based on the neighborhood name then set weights to the data to make it so one data point wasnt too important then I made a stacked bar graph based on neighborhood which added the most important data from each of our parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_new = df_new.reset_index()\n",
    "reset_fount = filtered_fountain.reset_index()\n",
    "reset_fount = reset_fount.rename(columns={'neighborhood': 'HOOD'})\n",
    "combDf = pd.merge(reset_new, reset_fount, on=\"HOOD\")\n",
    "\n",
    "#dogFriends = dogFriends.to_frame()\n",
    "\n",
    "dogFriends.columns =['barkDogs']\n",
    "df_dog = dogFriends.reset_index()\n",
    "df_dog.columns =['HOOD','barkDogs']\n",
    "combDf = pd.merge(combDf, df_dog, on=\"HOOD\")\n",
    "combDf.head(20)\n",
    "combDf['Shape__Are'] = combDf['Shape__Are'].apply(lambda x: x/100000)\n",
    "combDf['barkDogs'] = combDf['barkDogs'].apply(lambda x: x/2)\n",
    "combDf['amount_of_fountains'] = combDf['amount_of_fountains'].apply(lambda x: x*4)\n",
    "combDf.head(20)\n",
    "combDf = combDf.set_index('HOOD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combDf.head(20)\n",
    "combDf.plot.bar(title = \"total added data\", figsize = (12,12), stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Squirrel Hill South Wins!!!!!!\n",
    "After I added all the data into a dataframe then stacked the data for the neighborhoods on top op each other and accounted for weight of each factor it becomes clear that squirrel hill south is the winner based on its park area, amount of public fountains, and number of barking dogs in the neighborhood."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
